{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ap8718/Robots4Hospitals/blob/main/Gown_doff/gown_doff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFT7Be6tAyEJ",
    "outputId": "5e2f35c9-96bd-4e82-be45-55ec6c46d436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Robots4Hospitals'...\n",
      "remote: Enumerating objects: 2226, done.\u001b[K\n",
      "remote: Counting objects: 100% (241/241), done.\u001b[K\n",
      "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
      "remote: Total 2226 (delta 104), reused 241 (delta 104), pack-reused 1985\u001b[K\n",
      "Receiving objects: 100% (2226/2226), 772.71 MiB | 13.34 MiB/s, done.\n",
      "Resolving deltas: 100% (910/910), done.\n",
      "Checking out files: 100% (709/709), done.\n",
      "Collecting mediapipe\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/c6/cb43b4d35257270a428a7c8e8c10565bb9719eaa4a3a5f34442d77e02678/mediapipe-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37.7MB 63kB/s \n",
      "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (57.0.0)\n",
      "Installing collected packages: mediapipe\n",
      "Successfully installed mediapipe-0.8.5\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ap8718/Robots4Hospitals\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F8D7ob1D2Q_X"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def inference(box_list):\n",
    "  gown = incomplete_gown = False\n",
    "  incomplete_gown_list = []\n",
    "  for item in box_list:\n",
    "    if item[5] == 0:\n",
    "      gown = True\n",
    "    elif item[5] == 1:\n",
    "      incomplete_gown = True\n",
    "      xmin, ymin, xmax, ymax = item[:4]\n",
    "      l = []\n",
    "      l.extend((xmin, ymin, xmax, ymax))\n",
    "      incomplete_gown_list.append(l)\n",
    "  return gown, incomplete_gown, incomplete_gown_list\n",
    "\n",
    "def analyseGownDoffing(image, results, incomplete_gown, incomplete_gown_list):\n",
    "    h, w, c = image.shape\n",
    "    danger = False\n",
    "    danger_text = ''\n",
    "    points = np.array([])\n",
    "    if(results.pose_landmarks):\n",
    "        points = np.array([(data_point.x, data_point.y, data_point.z) for data_point in results.pose_landmarks.landmark])\n",
    "\n",
    "        #Left hand\n",
    "        cx15, cy15, cz15 = int(w*points[15][0]), int(h*points[15][1]), int(h*points[15][2])     #Left wrist\n",
    "        cx17, cy17, cz17 = int(w*points[17][0]), int(h*points[17][1]), int(h*points[17][2])     #Left pinky\n",
    "        cx19, cy19, cz19 = int(w*points[19][0]), int(h*points[19][1]), int(h*points[19][2])     #Left index\n",
    "        cx21, cy21, cz21 = int(w*points[21][0]), int(h*points[21][1]), int(h*points[21][2])     #Left thumb\n",
    "\n",
    "        #Left hand\n",
    "        cx16, cy16, cz16 = int(w*points[16][0]), int(h*points[16][1]), int(h*points[16][2])     #Right wrist\n",
    "        cx18, cy18, cz18 = int(w*points[18][0]), int(h*points[18][1]), int(h*points[18][2])     #Right pinky\n",
    "        cx20, cy20, cz20 = int(w*points[20][0]), int(h*points[20][1]), int(h*points[20][2])     #Right index\n",
    "        cx22, cy22, cz22 = int(w*points[22][0]), int(h*points[22][1]), int(h*points[22][2])     #Right thumb\n",
    "\n",
    "        cx11, cy11 = int(w*points[11][0]), int(h*points[11][1])     #Left shoulder\n",
    "        cx12, cy12 = int(w*points[12][0]), int(h*points[12][1])     #Right shoulder\n",
    "\n",
    "        cx13, cy13 = int(w*points[13][0]), int(h*points[13][1])     #Left elbow\n",
    "        cx14, cy14 = int(w*points[14][0]), int(h*points[14][1])     #Right elbow\n",
    "\n",
    "        cx23, cy23 = int(w*points[23][0]), int(h*points[23][1])     #Left hip\n",
    "        cx24, cy24 = int(w*points[24][0]), int(h*points[24][1])     #Right hip\n",
    "\n",
    "        height = int(abs(cy12 - cy24))\n",
    "\n",
    "        right_dist_elbow = int(abs(cx15 - cx14) + abs(cy15 - cy14))             #Manhattan distance\n",
    "        left_dist_elbow = int(abs(cx16 - cx13) + abs(cy16 - cy13))\n",
    "\n",
    "        right_dist_elbow /= height\n",
    "        left_dist_elbow /= height\n",
    "\n",
    "\n",
    "        right_dist_shoulder = int(abs(cy12 - cy24))          #Manhattan distance\n",
    "        left_dist_shoulder = int(abs(cy11 - cy23))           #Manhattan distance\n",
    "\n",
    "        scale = 1.07    # Hip to tip of shoulder / hip to middle of shoulder\n",
    "\n",
    "        right_dist_shoulder *= scale\n",
    "        left_dist_shoulder *= scale\n",
    "\n",
    "        cy12_new = int(cy24-right_dist_shoulder)\n",
    "        cy11_new = int(cy23-left_dist_shoulder)\n",
    "\n",
    "        #Neck\n",
    "        cx_neck, cy_neck = int((cx12 + cx11)/2), int((cy12_new + cy11_new)/2)\n",
    "\n",
    "        LHands = np.array([\n",
    "                [cx15, cy15],\n",
    "                [cx17, cy17],\n",
    "                [cx19, cy19],\n",
    "                [cx21, cy21],\n",
    "        ])\n",
    "        RHands = np.array([\n",
    "                [cx16, cy16],\n",
    "                [cx18, cy18],\n",
    "                [cx20, cy20],\n",
    "                [cx22, cy22],\n",
    "        ])\n",
    "\n",
    "        handColour = (0,255,0)\n",
    "\n",
    "        LhandWithinShoulders = np.logical_and(cx12 < LHands[:,0],  LHands[:,0] < cx11)\n",
    "        RhandWithinShoulders = np.logical_and(cx12 < RHands[:,0],  RHands[:,0] < cx11)\n",
    "\n",
    "        LhandAboveNeck = (cy_neck > LHands[:,1])\n",
    "        RhandAboveNeck = (cy_neck > RHands[:,1])\n",
    "\n",
    "        LhandOnTorso = np.logical_and(LHands[:,0] > cx12, LHands[:,0] < cx11).all() and np.logical_and(LHands[:,1] > cy12_new, LHands[:,1] < cy24).all()\n",
    "        RhandOnTorso = np.logical_and(RHands[:,0] > cx12, RHands[:,0] < cx11).all() and np.logical_and(RHands[:,1] > cy12_new, RHands[:,1] < cy24).all()\n",
    "\n",
    "        handOnTorso = False\n",
    "        if LhandOnTorso or RhandOnTorso:\n",
    "            handOnTorso = True\n",
    "\n",
    "        if LhandWithinShoulders.any() or RhandWithinShoulders.any():\n",
    "            # handColour = (0,127,255)\n",
    "            if sum(LhandAboveNeck) >= 3 or sum(RhandAboveNeck) >= 3:    # 2 or more points\n",
    "                danger = True\n",
    "                danger_text = 'Neck Touch Danger'\n",
    "\n",
    "        if(right_dist_elbow < 0.37 or left_dist_elbow < 0.37):\n",
    "            danger = True\n",
    "            danger_text = 'Arm Touch Danger'\n",
    "\n",
    "        if incomplete_gown:\n",
    "          for l in incomplete_gown_list:\n",
    "            xmin, ymin, xmax, ymax = l\n",
    "            xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "            cv2.rectangle(image, (xmin, ymax), (xmax, ymin), (255,255,255),3)\n",
    "            X_LhandWithinBoxes = np.logical_and(xmin < LHands[:,0],  LHands[:,0] < xmax)\n",
    "            Y_LhandWithinBoxes = np.logical_and(ymin < LHands[:,1],  LHands[:,1] < ymax)\n",
    "\n",
    "            X_RhandWithinBoxes = np.logical_and(xmin < RHands[:,0],  RHands[:,0] < xmax)\n",
    "            Y_RhandWithinBoxes = np.logical_and(ymin < RHands[:,1],  RHands[:,1] < ymax)\n",
    "\n",
    "            if not (X_LhandWithinBoxes.all() and Y_LhandWithinBoxes.all() and X_RhandWithinBoxes.all() and Y_RhandWithinBoxes.all()) and handOnTorso:\n",
    "              danger = True\n",
    "              danger_text = 'Hands Misposition Danger' #this condition is quite harsh, we will see..\n",
    "\n",
    "        if danger:\n",
    "            handColour = (0,0,255)\n",
    "\n",
    "        # Colours in BGR\n",
    "        cv2.circle(image, (cx15, cy15), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx17, cy17), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx19, cy19), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx21, cy21), 5, handColour, cv2.FILLED)\n",
    "\n",
    "        # cv2.line(image, (cx19, cy19), (cx7, cy7), (0, right_dist_shoulder, 255-right_dist_shoulder), 3)\n",
    "        cv2.circle(image, (cx16, cy16), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx18, cy18), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx20, cy20), 5, handColour, cv2.FILLED)\n",
    "        cv2.circle(image, (cx22, cy22), 5, handColour, cv2.FILLED)\n",
    "\n",
    "        cv2.circle(image, (cx12, cy12_new), 5, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(image, (cx11, cy11_new), 5, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(image, (cx_neck, cy_neck), 5, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "        cv2.line(image, (cx11, cy11_new), (cx12, cy12_new), (0, 255, 0), 1)\n",
    "\n",
    "        if danger:\n",
    "            cv2.putText(image, danger_text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return danger, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yB3kQ_XZCWxH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/arunansupatra/.cache/torch/hub/ultralytics_yolov5_master\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5 ðŸš€ 2021-6-9 torch 1.8.1 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "INPUT_MP4_PATH = '/content/gowndoff.mp4'\n",
    "OUTPUT_MP4_PATH = '/content/output.mp4'\n",
    "MODEL_PATH = 'gown_harsh.pt'\n",
    "cap = cv2.VideoCapture(INPUT_MP4_PATH)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fcount  = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "videoWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "videoHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(OUTPUT_MP4_PATH, fourcc, fps, (videoWidth,videoHeight))\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH)\n",
    "image_list = []\n",
    "\n",
    "    # Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    print(cap.isOpened())\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # Recolor Feed\n",
    "        if not ret:\n",
    "          print(\"EOF. Exited\")\n",
    "          break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.resize(image, dsize=(480, 320), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        res = model(image, size=640)\n",
    "        box_list = res.xyxy[0].tolist()\n",
    "        gown, incomplete_gown, incomplete_gown_list = inference(box_list)\n",
    "        if (not gown) and (not incomplete_gown):\n",
    "          cv2.putText(image, \"No Gown Detected\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 1, cv2.LINE_AA)\n",
    "          out.write(image)\n",
    "          continue\n",
    "\n",
    "        # Make Pose Detections\n",
    "        results = pose.process(image)\n",
    "        if not results.pose_landmarks:\n",
    "          cv2.putText(image, \"No Pose Detected\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 1, cv2.LINE_AA)\n",
    "          out.write(image)\n",
    "          continue\n",
    "          \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # Pose Detections\n",
    "        # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        danger, image = analyseGownDoffing(image_bgr, results, incomplete_gown, incomplete_gown_list)\n",
    "        image_list.append(image)\n",
    "        out.write(image)\n",
    "\n",
    "        #if danger:\n",
    "        #  print(\"DANGER\")\n",
    "        #cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J5hPJDp-HuCt",
    "outputId": "5e93db67-17e2-404b-ee51-d0787293ced8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cce535b7e466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "print(len(image_list))\n",
    "index = 0\n",
    "for i in image_list:\n",
    "  index += 1\n",
    "  if index < 200:\n",
    "    continue\n",
    "  cv2_imshow(i)\n",
    "\n",
    "  index += 9\n",
    "  if index > len(image_list):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMLB4dZ2JXrwEfQVBmzOqW+",
   "include_colab_link": true,
   "name": "gown_doff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
